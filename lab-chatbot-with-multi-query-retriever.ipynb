{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering with LangChain, OpenAI, and MultiQuery Retriever\n",
    "\n",
    "This interactive workbook demonstrates example of Elasticsearch's [MultiQuery Retriever](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html) to generate similar queries for a given user input and apply all queries to retrieve a larger set of relevant documents from a vectorstore.\n",
    "\n",
    "Before we begin, we first split the fictional workplace documents into passages with `langchain` and uses OpenAI to transform these passages into embeddings and then store these into Elasticsearch.\n",
    "\n",
    "We will then ask a question, generate similar questions using langchain and OpenAI, retrieve relevant passages from the vector store, and use langchain and OpenAI again to provide a summary for the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !python3 -m pip install -qU jq lark langchain langchain-elasticsearch langchain_openai tiktoken\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elasticsearch\n",
    "\n",
    "ℹ️ We're using an Elastic Cloud deployment of Elasticsearch for this notebook. If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial. \n",
    "\n",
    "We'll use the **Cloud ID** to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to https://cloud.elastic.co/deployments and select your deployment.\n",
    "\n",
    "We will use [ElasticsearchStore](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html) to connect to our elastic cloud deployment, This would help create and index data easily.  We would also send list of documents that we created in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
    "ELASTIC_CLOUD_ID = os.environ.get('ELASTIC_CLOUD_ID')\n",
    "\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
    "ELASTIC_API_KEY = os.environ.get('ELASTIC_API_KEY')\n",
    "\n",
    "# https://platform.openai.com/api-keys\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=\"elastic_ironhack\", #give it a meaningful name\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Data into Elasticsearch\n",
    "Let's download the sample dataset and deserialize the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/example-apps/chatbot-rag-app/data/data.json\"\n",
    "\n",
    "# Open the URL and the data\n",
    "response = urlopen(url)\n",
    "data = json.load(response)\n",
    "\n",
    "# Store the data in the vectorstore\n",
    "with open(\"temp.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Documents into Passages\n",
    "\n",
    "We’ll chunk documents into passages in order to improve the retrieval specificity and to ensure that we can provide multiple passages within the context window of the final question answering prompt.\n",
    "\n",
    "Here we are chunking documents into 800 token passages with an overlap of 400 tokens.\n",
    "\n",
    "Here we are using a simple splitter but Langchain offers more advanced splitters to reduce the chance of context being lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "page_content='Effective: March 2020\n",
      "Purpose\n",
      "\n",
      "The purpose of this full-time work-from-home policy is to provide guidelines and support for employees to conduct their work remotely, ensuring the continuity and productivity of business operations during the COVID-19 pandemic and beyond.\n",
      "Scope\n",
      "\n",
      "This policy applies to all employees who are eligible for remote work as determined by their role and responsibilities. It is designed to allow employees to work from home full time while maintaining the same level of performance and collaboration as they would in the office.\n",
      "Eligibility\n",
      "\n",
      "Employees who can perform their work duties remotely and have received approval from their direct supervisor and the HR department are eligible for this work-from-home arrangement.\n",
      "Equipment and Resources\n",
      "\n",
      "The necessary equipment and resources will be provided to employees for remote work, including a company-issued laptop, software licenses, and access to secure communication tools. Employees are responsible for maintaining and protecting the company's equipment and data.\n",
      "Workspace\n",
      "\n",
      "Employees working from home are responsible for creating a comfortable and safe workspace that is conducive to productivity. This includes ensuring that their home office is ergonomically designed, well-lit, and free from distractions.\n",
      "Communication\n",
      "\n",
      "Effective communication is vital for successful remote work. Employees are expected to maintain regular communication with their supervisors, colleagues, and team members through email, phone calls, video conferences, and other approved communication tools.\n",
      "Work Hours and Availability\n",
      "\n",
      "Employees are expected to maintain their regular work hours and be available during normal business hours, unless otherwise agreed upon with their supervisor. Any changes to work hours or availability must be communicated to the employee's supervisor and the HR department.\n",
      "Performance Expectations\n",
      "\n",
      "Employees working from home are expected to maintain the same level of performance and productivity as if they were working in the office. Supervisors and team members will collaborate to establish clear expectations and goals for remote work.\n",
      "Time Tracking and Overtime\n",
      "\n",
      "Employees are required to accurately track their work hours using the company's time tracking system. Non-exempt employees must obtain approval from their supervisor before working overtime.\n",
      "Confidentiality and Data Security\n",
      "\n",
      "Employees must adhere to the company's confidentiality and data security policies while working from home. This includes safeguarding sensitive information, securing personal devices and internet connections, and reporting any security breaches to the IT department.\n",
      "Health and Well-being\n",
      "\n",
      "The company encourages employees to prioritize their health and well-being while working from home. This includes taking regular breaks, maintaining a work-life balance, and seeking support from supervisors and colleagues when needed.\n",
      "Policy Review and Updates\n",
      "\n",
      "This work-from-home policy will be reviewed periodically and updated as necessary, taking into account changes in public health guidance, business needs, and employee feedback.\n",
      "Questions and Concerns\n",
      "\n",
      "Employees are encouraged to direct any questions or concerns about this policy to their supervisor or the HR department.' metadata={'source': 'C:\\\\Development\\\\_repos\\\\Ironhack\\\\Labs\\\\ik-lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 1, 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'name': 'Work From Home Policy', 'url': './sharepoint/Work from home policy.txt', 'created_on': '2020-03-01', 'updated_at': '2020-03-01', 'category': 'teams', '_run_ml_inference': True, 'rolePermissions': ['demo', 'manager']}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    #Populate the metadata dictionary with keys name, summary, url, category, and updated_at.\n",
    "    \n",
    "    for k, v in record.items():\n",
    "        if k != 'content':\n",
    "            metadata[k] = v\n",
    "    return metadata\n",
    "\n",
    "\n",
    "# For more loaders https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "# And 3rd party loaders https://python.langchain.com/docs/modules/data_connection/document_loaders/#third-party-loaders\n",
    "loader = JSONLoader(\n",
    "    file_path=\"temp.json\",          # Path to the JSON file\n",
    "    jq_schema=\".[]\",                # JSON schema\n",
    "    content_key=\"content\",          # Key for the content\n",
    "    metadata_func=metadata_func,    # Metadata function\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=800, chunk_overlap=400 #define chunk size and chunk overlap\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "print(len(docs))\n",
    "\n",
    "# print 1 document content\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk Import Passages\n",
    "\n",
    "Now that we have split each document into the chunk size of 800, we will now index data to elasticsearch using [ElasticsearchStore.from_documents](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html#langchain.vectorstores.elasticsearch.ElasticsearchStore.from_documents).\n",
    "\n",
    "We will use Cloud ID, Password and Index name values set in the `Create cloud deployment` step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Elastic vectorstore with the documents\n",
    "documents = vectorstore.from_documents(\n",
    "    docs,                           # list of documents\n",
    "    embeddings,                     # embeddings\n",
    "    index_name='elastic_ironhack',  # index name\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,   # cloud id\n",
    "    es_api_key=ELASTIC_API_KEY,     # api key\n",
    ")\n",
    "\n",
    "# define the language model\n",
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, max_tokens=500)\n",
    "\n",
    "# initialize the retriever\n",
    "retriever = MultiQueryRetriever.from_llm(vectorstore.as_retriever(), llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering with MultiQuery Retriever\n",
    "\n",
    "Now that we have the passages stored in Elasticsearch, we can now ask a question to get the relevant passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide information on the sales team at NASA?', '2. How does the sales team operate within NASA?', '3. What are the responsibilities of the NASA sales team?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Answer ----\n",
      "The NASA sales team is a part of the Americas region within the sales organization. It is led by two Area Vice-Presidents, Laura Martinez and Gary Johnson, who are responsible for managing the sales team in North America and South America respectively. The team is made up of dedicated account managers, sales representatives, and support staff who work together to identify and pursue new business opportunities, nurture existing client relationships, and ensure customer satisfaction. They also collaborate closely with other departments, such as marketing, product development, and customer support, to deliver high-quality products and services to clients in the Americas region.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import format_document\n",
    "\n",
    "import logging\n",
    "# Set the logging level to INFO for the retriever\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "# Define the prompt templates\n",
    "LLM_CONTEXT_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved\n",
    "    context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Be as verbose and educational in your response as possible. \n",
    "    \n",
    "    context: {context}\n",
    "    Question: \"{question}\"\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define the document prompt template\n",
    "LLM_DOCUMENT_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ---\n",
    "    SOURCE: {name}\n",
    "    {page_content}\n",
    "    ---\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def _combine_documents(docs, document_prompt=LLM_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    \"\"\"Combine multiple documents into a single string with a separator between each document.\n",
    "\n",
    "    Args:\n",
    "        docs: List of documents to combine.\n",
    "        document_prompt: prompt template to use for each document.\n",
    "        document_separator: separator to use between each document.\n",
    "\n",
    "    Returns:\n",
    "        str: combined documents.\n",
    "    \"\"\"\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "_context = RunnableParallel(\n",
    "    context=retriever | _combine_documents,\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "chain = _context | LLM_CONTEXT_PROMPT | llm\n",
    "\n",
    "ans = chain.invoke(\"what is the nasa sales team?\")\n",
    "\n",
    "print(\"---- Answer ----\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate at least two new iteratioins of the previous cells - Be creative.** Did you master Multi-\n",
    "Query Retriever concepts through this lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What are the fundamental principles that guide our organization?', '2. Can you tell me about the key beliefs that define our company?', \"3. What are the central ideals that shape our company's culture?\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Answer ----\n",
      "- Our core values include integrity, teamwork, excellence, innovation, and respect.\n",
      "    - We strive to create a diverse, inclusive, and supportive work environment.\n",
      "    - We encourage creativity and embrace change to stay ahead in the market.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt templates\n",
    "LLM_CONTEXT_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for summarizing information into bullet points. Use the following pieces\n",
    "    of retrieved context to generate a summarized answer to the question, in 3 clear bullet-points. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Bullet points should be brief and only contains the most relevant keywords. \n",
    "    \n",
    "    context: {context}\n",
    "    Question: \"{question}\"\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define the document prompt template\n",
    "LLM_DOCUMENT_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ---\n",
    "    SOURCE: {name}\n",
    "    {page_content}\n",
    "    ---\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def _combine_documents(docs, document_prompt=LLM_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    \"\"\"Combine multiple documents into a single string with a separator between each document.\n",
    "\n",
    "    Args:\n",
    "        docs: List of documents to combine.\n",
    "        document_prompt: prompt template to use for each document.\n",
    "        document_separator: separator to use between each document.\n",
    "\n",
    "    Returns:\n",
    "        str: combined documents.\n",
    "    \"\"\"\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "_context = RunnableParallel(\n",
    "    context=retriever | _combine_documents,\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "chain = _context | LLM_CONTEXT_PROMPT | llm\n",
    "\n",
    "ans = chain.invoke(\"What are our core values?\")\n",
    "\n",
    "print(\"---- Answer ----\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide a detailed explanation to our new client Mr. John Doe on the location and proper usage of the TD1 form?', '2. How can Mr. John Doe access and effectively utilize the TD1 form? Please provide a step-by-step guide.', '3. In what ways can you assist our new client Mr. John Doe in locating and utilizing the TD1 form? Please provide clear instructions.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Answer ----\n",
      "\n",
      "Dear Mr. John Doe,\n",
      "\n",
      "I hope this email finds you well. As a new employee in Canada, it is important for you to understand how to update your tax elections forms to ensure accurate tax deductions from your pay. This guide will provide you with the necessary information on how to access and complete the TD1 Personal Tax Credits Return form.\n",
      "\n",
      "Firstly, the TD1 form can be found on the Canada Revenue Agency (CRA) website. Your employer may also provide you with a paper copy or a link to the online form. To access the form directly, please use the following link: https://www.canada.ca/en/revenue-agency/services/forms-publications/td1-personal-tax-credits-returns.html\n",
      "\n",
      "Once you have accessed the form, please make sure to select the correct version based on your province or territory of residence. It is important to fill out both the federal TD1 form and, if applicable, the provincial or territorial TD1 form.\n",
      "\n",
      "For the best experience, we recommend downloading and opening the form in Adobe Reader. If you have visual impairments, a large print version is available on the CRA website.\n",
      "\n",
      "Next, please fill out the form by entering your personal information, such as your name, Social Insurance Number (SIN), and address. Then, go through each section to claim any personal tax credits that apply to you. These credits may include the basic personal amount, amount for an eligible dependant, amount for infirm dependants age 18 or older, caregiver amount, disability amount, and tuition and education amounts. Please read the instructions carefully for each section to ensure you claim the correct amounts.\n",
      "\n",
      "Once you have completed the form, please sign and date it at the bottom. You can then submit the form to your employer either electronically or in print. Your employer will use the information on your TD1 form to calculate the correct amount of tax to be deducted from your pay.\n",
      "\n",
      "Please remember to update your TD1 form whenever your personal circumstances change, such as getting married, having a child, or becoming eligible for a new tax credit. This will ensure accurate tax deductions from your pay.\n",
      "\n",
      "Thank you for choosing our company and we look forward to working with you.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt templates\n",
    "LLM_CONTEXT_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for generating emails about a given topic. Use the following pieces\n",
    "    of retrieved context to generate the content of the email. Add the usual email intro and ending.\n",
    "    The tone should be formal, it's for a professional email. The email should be brief and straight to the point.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    \n",
    "    context: {context}\n",
    "    Question: \"{question}\"\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define the document prompt template\n",
    "LLM_DOCUMENT_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ---\n",
    "    SOURCE: {name}\n",
    "    {page_content}\n",
    "    ---\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def _combine_documents(docs, document_prompt=LLM_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    \"\"\"Combine multiple documents into a single string with a separator between each document.\n",
    "\n",
    "    Args:\n",
    "        docs: List of documents to combine.\n",
    "        document_prompt: prompt template to use for each document.\n",
    "        document_separator: separator to use between each document.\n",
    "\n",
    "    Returns:\n",
    "        str: combined documents.\n",
    "    \"\"\"\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "_context = RunnableParallel(\n",
    "    context=retriever | _combine_documents,\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "chain = _context | LLM_CONTEXT_PROMPT | llm\n",
    "\n",
    "ans = chain.invoke(\"Explain to our new client Mr. John Doe where to find and how to use the TD1 form.\")\n",
    "\n",
    "print(\"---- Answer ----\")\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
